URL
	统一资源定位符

HTML
	超文本

HTTP/HTTPS


GET/POST


Usee-agent
Referer	此内容标示请求是从哪个页面发过来的，一般用于来源统计、防盗链、反爬虫处理等

HTTP状态码
	4xx
	5xx
	
响应头

响应体


请求：
    请求方式   get post
    请求url    网页分析
    请求头     user-agent  referer cookie  content-type
    请求体     表单信息-post
    
响应：
    状态码     200 3xx 404 5xx
    响应头     主要是获取cookie信息
    响应体     要爬取的内容主体 html json 二进制流



提取数据
    根据源码提取信息
        1、正则
        2、css选择器、xpath
        3、库 Beautiful Soup、pyquery、lxml
        
数据保存
    保存到文件：txt，json
    保存到数据库：mysql、MongoDB
    
    
自动化爬取
    要考虑异常、续爬、重复爬等问题

参考
www.runoob.com


代理
    用代理的方法实现伪装ip
    
    
Robo 3T     mongodb可视化工具


实例：
    from urllib import request
    response = request.urlopen('https://www.douban.com/')
    print(type(response))       #获取响应信息的类型
    print(response.status)      #获取状态码
    print(response.getheaders)  #获取响应中的响应头
    print(response.getheader('Date'))   #获取响应头中的Date字段的值
    print(response.read().decode('utf-8'))  #读取响应体的内容，以utf8解码


urllib.request.Request(url, data=None, headers={}, origin_req_host, )





url拼接
>>> from urllib import parse
>>> wd = '机器学习'
>>> url = 'https:www.baidu.com/s?wd='+ parse.quote(wd)
>>> print(url)
https:www.baidu.com/s?wd=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0


反编码
s = '%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0'
parse.unquote(s)


用字典分段拼接
base_url = 'https://www.lagou.com/jobs.positonAjax.json?'
params = {
    'px': 'default',
    'city': '深圳',
    'Result': 'false'
}
url = base_url + parse.urlencode(params)
print(url)



