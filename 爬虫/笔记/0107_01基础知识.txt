1、工具
    jupyter 类似一个阅读器
        安装anaconda就自带有jupyter
        打开：jupyter notebook

    mongodb数据库
        pip install pymongo
        
    redis数据库
        pip install pymongo
        
        import redis
        redis.VERSION
        
        
    Robo 3T     mongodb可视化工具

        

URL
	URI 统一资源标志符,Uniform Resource Identifier
	URL 统一资源定位符，Universal Resource Locator

HTML
	超文本 hypertext

HTTP/HTTPS
    HTTP    Hyper Text Transfer Protocol    超文本传输协议
    HTTPS   安全的超文本传输协议


请求GET/POST
    HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法。
    HTTP1.1新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT 方法。


请求头
    说明服务器要使用的附加信息，重要的由cookie，referer，user-agent
    Accept  请求报头域，用于指定客户端可接收哪些类型的信息
    Accept-Language 客户端可接受的语言类型
    Accept-Encoding 客户端可接受的内容编码
    Host            用于指定请求资源的主机IP和端口号，其内容为请求URL的原始服务器或网关的位置
    Cookie/Cookies  这是网站为了辨别用户进行会话跟踪而存储在用户本地的数据，要功能是维持当前访问会话
    Referer         标识请求是从哪个页面发过来的，一般用于来源统计、防盗链、反爬虫处理等
    User-Agent      用户信息
    Content-Type    表示请求中的每天类型信息，例如，text/html代表HTML格式，image/gif代表GIF图片，application/json代表JSON类型
    
    
请求体
    请求体一般承载的是POST请求中的表单数据，对于GET请求，请求体则为空；
    
    
    
响应
    1、响应状态码
        200 - 请求成功
        301 - 资源（网页等）被永久转移到其它URL
        404 - 请求的资源（网页等）不存在
        500 - 内部服务器错误
    
    
    2、响应头
        参考：http://www.runoob.com/http/http-header-fields.html
        Allow	服务器支持哪些请求方法（如GET、POST等）。
    
    
    3、响应体
        做爬虫请求网页后，要解析的内容就是响应体。

请求：
    请求方式   get post
    请求url    网页分析
    请求头     user-agent  referer cookie  content-type
    请求体     表单信息-post
    
响应：
    状态码     200 3xx 404 5xx
    响应头     主要是获取cookie信息
    响应体     要爬取的内容主体 html json 字节流bytes



爬虫原理
    1、获取网页
        urllib、request等库
    2、提取数据
        根据源码提取信息
            1、正则
            2、css选择器、xpath
            3、库 Beautiful Soup、pyquery、lxml
            
    数据保存
        保存到文件：txt，json
        保存到数据库：mysql、MongoDB
        
        
    自动化爬取
        要考虑异常、续爬、重复爬等问题


Session和Cookie
    两个用于保持HTTP连接状态的技术，它们分别是会话和Cookies。
    
    Session在服务端，也就是网站的服务器，用来保存用户的会话信息；会话对象用来存储特定用户会话所需的属性及配置信息。这样，当用户在应用程序的Web页之间跳转时，存储在会话对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当用户请求来自应用程序的Web页时，如果该用户还没有会话，则Web服务器将自动创建一个会话对象。当会话过期或被放弃后，服务器将终止该会话。
    Cookies在客户端，也可以理解为浏览器端，有了Cookies，浏览器在下次访问网页时会自动附带上它发送给服务器，服务器通过识别Cookies并鉴定出是哪个用户，然后再判断用户是否是登录状态，然后返回对应的响应。




代理
    用代理的方法实现伪装ip
    在我们正常请求一个网站时，是发送了请求给Web服务器，Web服务器把响应传回给我们。如果设置了代理服务器，实际上就是在本机和服务器之间搭建了一个桥，此时本机不是直接向Web服务器发起请求，而是向代理服务器发出请求，请求会发送给代理服务器，然后由代理服务器再发送给Web服务器，接着由代理服务器再把Web服务器返回的响应转发给本机。这样我们同样可以正常访问网页，但这个过程中Web服务器识别出的真实IP就不再是我们本机的IP了，就成功实现了IP伪装，这就是代理的基本原理。
    
    




参考
www.runoob.com
