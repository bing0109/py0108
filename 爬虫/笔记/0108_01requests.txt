昨日回顾

爬虫基础知识
1、http过程：请求过程、响应过程
    1.1请求过程
        a 请求方式 get/post
        b 请求url
        c 请求头
            user-agent
            referer
            cookie
        d 请求体
            post方式有请求体、get没有
    1.2响应过程
        a 状态码
            200 请求成功
            3xx 重定向
            4xx 客户端或网络问题
            5xx 服务器的问题
        b 响应头
            记录cookie等信息
        c 响应体
            html、json、字节流等
        
2、爬虫
    发请求，获取响应，提取响应信息，保存提取出来的信息
    
    2.1 模拟请求，接收响应
        urllib/requests/selenium
    2.2 提取信息
        html：正则表达式，css选择器，xpath选择器
            beautiful soup、pyquery
        json：python中的json模块
        图片、视频、音乐：都是二进制流的形式，直接保存即可
    2.3 保存信息
        文本：txt、csv、json等格式
        数据库：mysql、mongodb、redies


3、urllib请求库
    urllib.request  请求模块，执行请求的操作
    urllib.parse    解析url（编码、拆分、合并）
    urllib.error    异常处理

    3.1 urllib.request
        1、response = urllib.request.urlopen(url, data=None, timeout)        执行请求
            url     可以输入str，即请求的url；还可以输入Request对象
            data    请求体，只能接受Bytes类型的数据，如果是None，那就是get请求，不为空就是post请求。
            timeout 超时的设置，单位是秒
            response是接收到的HttpResponse对象
        2、urllib.request.Request(url, data=None,headers={},method)
            Request对象，可以方便添加请求头
            headers 请求头，可以接收字典格式
            method  请求方式，如果data=None，默认是get请求
        
    3.2 获得响应
        response=urllib.request.Request(url, data=None,headers={},method)
            是接收到的HttpResponse对象
        response.read() 读取响应体，返回的是二进制
        response.read().decode('utf8')  返回的是字符串
        response.status 获取状态码
        response.getheaders()   获取响应头
        response.getheader('name')  获取响应头中的某个字符串


    3.3 urllib.parse
        urllib.parse.urlencode(dict)    url编码，输入是字典
        urllib.parse.quote(str)     url编码，输入的是字符串
        urllib.parse.unquote(str)   url反编码

    3.4 urllib.error
        urllib.error.URLError
        urllib.error.HTTPError  是URLError的子类
        进行异常捕获的时候，一般是先子类，后父类；先子类可获取更细分的处理




requests
参考 http://localhost:8888/notebooks/bing/%E7%88%AC%E8%99%AB/%E8%AF%BE%E4%BB%B6/%E5%9F%BA%E7%A1%80/3.%20%E5%9F%BA%E6%9C%AC%E5%BA%93%E4%B9%8BRequests.ipynb

    params = {
        'wd': '人工智能',
        'hello': 'world'
    }
    url = 'http://httpbin.org/get'
    res6 = requests.get(url=url, params=params)

    print(res6.text)     # 返回响应对象，主要用于获取文本
    print(res6.content)  # 返回响应对象，结果前带有一个b，这代表是bytes类型的数据，主要用于获取 图片、文件等





三者的区别详细请参考test.py文件

urllib.request.urlopen()
    from urllib import request
    response = request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)
        url 打开URL，可以接受一个字符串的URL，或者一个Request对象
        data 该参数是可选的。如果要添加该参数，并且如果它是字节流编码格式的内容，即bytes类型，则需要通过bytes()方法转化。另外，如果传递了这个参数，则它的请求方式就不再是GET方式，而是POST方式。
        timeout 该参数用于设置超时时间，单位为秒


urllib.request.Request()
    from urllib import request
    response = request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)

requests
    import requests
    res1 = requests.get('http://httpbin.org/')

    url = 'http://httpbin.org/put'
    data = {'abc':124, 'cde':'ertert'}
    res2 = requests.post(url=url,date=data,params=params,)
























