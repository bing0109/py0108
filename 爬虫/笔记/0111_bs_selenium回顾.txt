
BeautifulSoup

1、解析器
    soup = BeautifulSoup(html, 'html.parser') # python标准库的解析器，只能针对html字符串    
    soup = BeautifulSoup(html, 'html.parser') # lxm解析器，执行速度快，
    
2、节点选择器
    soup.p      #定位到p标签，针对节点名称进行定位，返回满足要求的第一条
    soup.p.a    # 也可以进行嵌套

3、提取信息
    1 获取文本信息
        soup.p.get_txt()
        soup.p.string
    2 获取属性信息
        soup.p.attrs['name']    # 获取标签p的name属性的值
        soup.p['name']  #同上
        soup.p.attrs    # 返回的是字典，包含节点所有的属性信息
       
4、关联选择器
    1 子节点，子孙节点
        soup.p.children/soup.p.contents # 获取子节点
        soup.p.decendants               # 获取子孙节点
    2 父节点，祖先节点
        soup.p.parent   # 获取父节点
        soup.p.parents  # 获取祖先节点
    3、兄弟节点
        soup.p.previous_sibling     # 最近的前面的一个兄弟节点
        soup.p.previous_siblings    # 获取前面的所有兄弟节点   返回生成器
        soup.p.next_sibling         # 获取最近的后面的一个兄弟节点
        soup.p.next_siblings        # 获取后面的所有的兄弟节点
        
5、方法选择器
    soup.find_all(name, attrs, text)    #返回所有满足要求的节点，返回list
       name：标签名称
       attrs：属性，例如 attrs={'class': 'classname'}，常用属性有id/class_,可以直接用值进行定位
            eg  class_=classname
       text：text可以输入字符串，也可以接收正则re.compile()

    soup.find(name, attrs, text)
        只返回第一个满足邀请的节点
        
6、CSS选择器
    soup.select('element .class #id')


所有的选择器都可以嵌套使用





selenium

    1、声明浏览器
        from selenium import webdriver
        browser = webdriver.Chrom()
    2、访问网址
        browser.get('http://www.baidu.com')
        browser.page_source     # 获取渲染之后的html源码字符串
        
    3、查找节点
        查找单个节点，返回满足要求的第一个节点
            browser.find_element_by_css_selector('#id .class tag')  #基于css选择器查找节点
            browser.find_element_by_id('idname')    #基于属性id的名称查找节点
            
            from selenium.webdriver.common.by import By
            browser.find_element(By.CSS_SELECTOR, '#id .class tag')#基于css选择器查找节点
        
        查找多个节点，返回满足要求的所有节点
            browser.find_elements_by_css_selector('#id .class tag')  #基于css选择器查找节点
            browser.find_elements_by_id('idname')    #基于属性id的名称查找节点
            
            from selenium.webdriver.common.by import By
            browser.find_elements(By.CSS_SELECTOR, '#id .class tag')#基于css选择器查找节点
        
4、获取信息
    a = browser.find_element_by_css_selector('#id .class tag')  
        a是查找到的某个节点
    a.get_attribut('attr_name') # 获取属性信息
    a.text  # 获取文本信息
    
5、节点交互
    a.send_keys('kw')   # 输入文本信息，一般是输入框的操作
    a.clear()           # 清空文本框
    
    b.click()           # 点击操作，一般是针对按钮
    
6、动作链
    from selenium.webdriver import ActionChains
    chain = ActionChains(browser)       # 声明动作链
    eg 一系列的动作：拖拽，双击等
        
        chain.perform()

7、execute_script
    eg.拖拽滚动条到底
    browser.execute_script()


8、延时等待
    1 隐式等待
        browser.implicitly_wait(10) 
            # 针对后面出现的所有find_element(s),如果查到到了，就继续执行后面的动作，如果没查到就继续等待10s，超出10s就抛出异常
    
    2 显示等待
        可以做判断，也可以查找节点，接收到变量中
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        wait = WebDriverWait(browser,10)
        c = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '')))   #对某个节点进行判断
            判断方式
            EC.presence_of_element_located  # 判读某个节点是否存在
            EC.element_to_be_clickable  # 判断某个节点是否可以被点击
            EC.text_to_be_present_in_element    #判断某个节点是否包含某个文本

9、前进后退
    browser.back()      # 后退
    browser.forward()   # 前进
    
10、cookie
    browser.get_cookie()        # 获取cookie
    browser.add_cookie(dict)    # 添加cookie， 接收字段格式
    browser.delete_all_cookie() # 清空cookie


11、异常
    from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException
    TimeoutException
        # 超时异常，出现在显示等待超时后
    NoSuchElementException
        # find_element(s)没有查到到节点时抛出的异常
    StaleElementReferenceException
        # 主要出现在js渲染时，已经查到的节点进行交互时，出现失焦，抛出的异常


12、选项卡
    browser.execute_script('window.open()')     # 打开一个选项卡
    browser.switch_to_window(browser.window_handles[1])  # 切换到一个选项卡窗口，之后就可以在新的选项卡窗口操作






